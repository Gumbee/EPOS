# compare standard gradient descent with adam GD

init-out = output-data/EMaxImprovementAggregator.m
init-numExperiments = 20
init-numIterations = 100
init-numUser = 1000
init-architecture.priority = HIGH_RANK
init-architecture.rank = RANK
init-architecture.type = SORTED_HtL
init-architecture.rankGenerator = RandomRank
init-costSignal = zero
init-measure = std
# measure same as cost function

init-architecture.balance = WEIGHT_BALANCED
plot-architecture.maxChildren = 2
plot-dataset = B8, E5.1
comp-agentFactory = IGreedy
#comp-outputMovie = false

list-config1 = MinCostGmA(var,m/n-m,sum), MinCostAdamGmA(var,m/n-m,sum)
plot-fitnessFunction = config1

comp-aggregator = maxImprovement